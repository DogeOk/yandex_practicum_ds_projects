{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Импорт-данных\" data-toc-modified-id=\"Импорт-данных-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Импорт данных</a></span></li><li><span><a href=\"#Загрузка-данных\" data-toc-modified-id=\"Загрузка-данных-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Загрузка данных</a></span></li><li><span><a href=\"#Вывод-первых-строк-датафрейма\" data-toc-modified-id=\"Вывод-первых-строк-датафрейма-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Вывод первых строк датафрейма</a></span></li><li><span><a href=\"#Вывод-основной-информации\" data-toc-modified-id=\"Вывод-основной-информации-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Вывод основной информации</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Подготовка-данных\" data-toc-modified-id=\"Подготовка-данных-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Подготовка данных</a></span></li><li><span><a href=\"#Токенизация-текста\" data-toc-modified-id=\"Токенизация-текста-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Токенизация текста</a></span></li><li><span><a href=\"#Создание-эмбедингов\" data-toc-modified-id=\"Создание-эмбедингов-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Создание эмбедингов</a></span></li><li><span><a href=\"#Подготовка-признаков\" data-toc-modified-id=\"Подготовка-признаков-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Подготовка признаков</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп» с использованием BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка\n",
    "### Импорт данных\n",
    "Импортирую необходимые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import transformers\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных\n",
    "Загружаю данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv('/datasets/toxic_comments.csv', index_col=0)\n",
    "except:\n",
    "    data = pd.read_csv('https://code.s3.yandex.net/datasets/toxic_comments.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод первых строк датафрейма\n",
    "Вывод первых строк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод основной информации\n",
    "Вывожу информацию о датафрейме"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также вывожу процент положительных значений в целевом признаке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10161213369158527"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наблюдаю дисбаланс данных. Его необходимо будет учесть при обучении\n",
    "\n",
    "**Вывод раздела.** В данном разделе были импортированы основные билиотеки, загружены данные и просмотрена основная информация о них."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение\n",
    "### Подготовка данных\n",
    "Урежу данные до 159000 для упрощения подбора размера батчей в будущем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(3000, random_state=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяю сохранение пропорций целевого признака"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10633333333333334"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С пропорциями всё хорошо.\n",
    "\n",
    "Указываю путь до модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'unitary/toxic-bert'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Токенизация текста\n",
    "Создаю токенизатор `BertTokenizer` и назначаю максимальную длину токена - 512, так как BERT работает именно с такой длиной токена. Токенизирую весь текст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "428f73258a30462c9b08e0af6ab36670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Apply progress:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = transformers.BertTokenizer.from_pretrained(path)\n",
    "\n",
    "tqdm.pandas(desc='Apply progress')\n",
    "tokenized = data['text'].progress_apply(\n",
    "    lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=512, truncation=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токены имеют разную длину, поэтому в рядах, где длина токена не достигает 512, заполняю токен нулями до необходимой длины. Также создаю маску для важных токенов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 512\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "\n",
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание эмбедингов\n",
    "Для создания эмбедингов инициализирую модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at unitary/toxic-bert were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = transformers.BertModel.from_pretrained(path).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Указываю размер батча и получаю эмбединги для текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfbf29b8f22c410e907fe6549676ddb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "embeddings = []\n",
    "for i in tqdm(range(padded.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]).cuda()\n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)]).cuda()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка признаков\n",
    "Собираю эмбединги в матрицу признаков, а также выделяю целевой признак из датафрейма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.concatenate(embeddings)\n",
    "target = data['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делю данные на тренировачную валидационную и тестовую выборки с соотношением 3:1:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features,\n",
    "    target,\n",
    "    test_size=0.6,\n",
    "    random_state=1\n",
    ")\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(\n",
    "    features_valid,\n",
    "    target_valid,\n",
    "    test_size=0.5,\n",
    "    random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ищу лучшую модель перебором гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DecisionTreeClassifier (max_depth):   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DecisionTreeClassifier (samples_leaf):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DecisionTreeClassifier (samples_leaf):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DecisionTreeClassifier (samples_leaf):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DecisionTreeClassifier (samples_leaf):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DecisionTreeClassifier (samples_leaf):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DecisionTreeClassifier (samples_leaf):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RandomForestClassifier (max_depth):   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RandomForestClassifier (n_estimators):   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RandomForestClassifier (n_estimators):   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RandomForestClassifier (n_estimators):   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RandomForestClassifier (n_estimators):   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RandomForestClassifier (n_estimators):   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RandomForestClassifier (n_estimators):   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая модель: RandomForestClassifier(n_estimators=150, max_depth=5)\n",
      "F1_SCORE: 0.8844221105527638\n"
     ]
    }
   ],
   "source": [
    "# Переменные для хранения параметров наилучшей модели\n",
    "best_model = 0\n",
    "best_model_title = 0\n",
    "# Начинаю с оценки логистической регрессии, так как она не требует перебора гиперпараметров\n",
    "model = LogisticRegression(random_state=1, class_weight='balanced', max_iter=1000)\n",
    "model.fit(features_train, target_train)\n",
    "# Сохраняю оценку, как лучшую, так как это первая модель\n",
    "best_score = f1_score(target_valid, model.predict(features_valid))\n",
    "best_model = model\n",
    "best_model_title = 'LogisticRegression'\n",
    "# Дерево решений\n",
    "# Цикл для перебора гиперпараметров модели дерева решений\n",
    "for depth in tqdm(range(5, 31, 5), desc='DecisionTreeClassifier (max_depth)', position=0, leave=False):\n",
    "    for samples_leaf in tqdm(range(1, 51), desc='DecisionTreeClassifier (samples_leaf)', position=1, leave=False):\n",
    "        model = DecisionTreeClassifier(min_samples_leaf=samples_leaf, max_depth=depth, class_weight='balanced', random_state=1)\n",
    "        model.fit(features_train, target_train)\n",
    "        score = f1_score(target_valid, model.predict(features_valid))\n",
    "        if best_score < score:\n",
    "            best_model = model\n",
    "            best_model_title = f'DecisionTreeClassifier(min_samples_leaf={samples_leaf}, max_depth={depth})'\n",
    "            best_score = score\n",
    "# Случайный лес\n",
    "# Цикл для перебора гиперпараметров модели случайного леса\n",
    "for depth in tqdm(range(5, 31, 5), desc='RandomForestClassifier (max_depth)', position=0, leave=False):\n",
    "    for est in tqdm(range(100, 501, 50), desc='RandomForestClassifier (n_estimators)', position=1, leave=False):\n",
    "        model = RandomForestClassifier(n_estimators=est, max_depth=depth, class_weight='balanced', random_state=1)\n",
    "        model.fit(features_train, target_train)\n",
    "        score = f1_score(target_valid, model.predict(features_valid))\n",
    "        if best_score < score:\n",
    "            best_model = model\n",
    "            best_model_title = f'RandomForestClassifier(n_estimators={est}, max_depth={depth})'\n",
    "            best_score = score\n",
    "# Вывод лучшей модели и её параметров для целевого признака\n",
    "print(f'Лучшая модель: {best_model_title}')\n",
    "print(f'F1_SCORE: {best_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9719626168224299"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обучаю лучшую модель\n",
    "best_model.fit(features_train, target_train)\n",
    "# Вывожу финальную оценку модели\n",
    "f1_score(target_test, best_model.predict(features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучашя модель проходит пороговое значение.\n",
    "\n",
    "**Вывод раздела.** В данном разделе был проведён малый срез данных для удобства работы с батчами, проведена токенизация, получены эмбединги, разделены признаки и обучены модели и выбрана наилучшая модель. Модель проходит необходимый порог."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы\n",
    "Целью данной работы было обучить модель классифицировать комментарии на позитивные и негативные для интернет-магазина «Викишоп». Для достижения данной цели были выполнены следующие задачи:\n",
    "+ подготовлены и загружены данные;\n",
    "+ просмотрена основная информация о данных;\n",
    "+ токенизирован текст;\n",
    "+ получены эмбединги;\n",
    "+ данные разделены на тренировачную и тестовую выборки в соотношении 3:1:1;\n",
    "+ перебором гиперпараметров найдена лучшая модель;\n",
    "+ лучшая модель прошла порог.\n",
    "\n",
    "В результате данной работы получены две модели машинного обучения, которые проходят необходимый порог `f1_score` в 0.75, а значит цель работы была достигнута."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 467,
    "start_time": "2023-06-14T07:31:16.693Z"
   },
   {
    "duration": 2015,
    "start_time": "2023-06-14T07:32:18.246Z"
   },
   {
    "duration": 21,
    "start_time": "2023-06-14T07:32:25.679Z"
   },
   {
    "duration": 44,
    "start_time": "2023-06-14T07:32:35.082Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-14T07:32:52.005Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
